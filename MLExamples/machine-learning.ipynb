{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io as io\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "\n",
    "def verbose(text):    \n",
    "    clear_output(wait=True)    \n",
    "    print(text)\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "def errorfill(x, y, yerr, color=None, label=None, alpha_fill=0.3, ax=None):\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "    if color is None:\n",
    "        color = ax._get_lines.get_next_color()\n",
    "    if np.isscalar(yerr) or len(yerr) == len(y):\n",
    "        ymin = y - yerr\n",
    "        ymax = y + yerr\n",
    "    elif len(yerr) == 2:\n",
    "        ymin, ymax = yerr\n",
    "    ax.plot(x, y, color=color, label=label)\n",
    "    ax.fill_between(x, ymax, ymin, color=color, label=label, alpha=alpha_fill)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../shareddata/Project_ASD/ERPs.npz'\n",
    "# filename = '../shareddata/Project_ASD/ERPs-b50.npz'\n",
    "# filename = '../shareddata/Project_ASD/ERPs-b100.npz'\n",
    "data = np.load(filename, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_asd_ = data['ERPs_ASD'] # [participants, catch/target, C1/C2/C3/C4]\n",
    "X_typ_ = data['ERPs_TYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_asd = X_asd_.shape[0]\n",
    "n_typ = X_typ_.shape[0]\n",
    "n_elec, n_t, _ = X_asd_[0,0,0].shape\n",
    "\n",
    "X_all = np.zeros((2,4,n_asd+n_typ,n_t,n_elec)) # catch/target | C1/C2/C3/C4\n",
    "y = np.concatenate((np.zeros(n_asd),np.ones(n_typ)))\n",
    "\n",
    "for k in range(4):\n",
    "    X_all[0,k] = np.concatenate([X_asd_[i,0,k].mean(2, keepdims=True)\n",
    "                                 for i in range(n_asd)]+\n",
    "                                [X_typ_[i,0,k].mean(2, keepdims=True)\n",
    "                                 for i in range(n_typ)],2).T\n",
    "    X_all[1,k] = np.concatenate([X_asd_[i,1,k].mean(2, keepdims=True)\n",
    "                                 for i in range(n_asd)]+\n",
    "                                [X_typ_[i,1,k].mean(2, keepdims=True)\n",
    "                                 for i in range(n_typ)],2).T\n",
    "idx = np.isnan(X_all.mean((0,1,3,4)))==False\n",
    "X_all = X_all[:,:,idx]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tc, n_conds, n_participants, n_t, n_elec = X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "lr = 1\n",
    "test_pca = np.arange(1,38,1)\n",
    "test_C = np.logspace(-5, 0, 6)\n",
    "n_C = test_C.shape[0]\n",
    "n_pca = test_pca.shape[0]\n",
    "\n",
    "if lr:\n",
    "    clf = LogisticRegression(max_iter=5000, tol=1.0)\n",
    "    param_grid = {\n",
    "        'pca__n_components': test_pca,\n",
    "        'clf__C': ,\n",
    "    }\n",
    "else:\n",
    "    clf = LinearDiscriminantAnalysis(tol=1e-3)\n",
    "    param_grid = {\n",
    "        'pca__n_components': test_pca,\n",
    "    }\n",
    "\n",
    "# clf = QuadraticDiscriminantAnalysis(tol=1e-3)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clf)])\n",
    "# search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_all = np.zeros((n_tc,n_conds), dtype=object)\n",
    "for i in range(n_tc):\n",
    "    for j in range(n_conds):\n",
    "        X = X_all[i,j].reshape(n_participants,n_t*n_elec)\n",
    "        \n",
    "        # using also squared signal improve performances\n",
    "        #X = np.concatenate([X_all[i,j].reshape(n_participants,n_t*n_elec),\n",
    "        #                   X_all[i,j].reshape(n_participants,n_t*n_elec)**2],\n",
    "        #                   axis=1)\n",
    "        \n",
    "        X -= X.mean(0, keepdims=True)\n",
    "        X /= X.std(0, keepdims=True)\n",
    "        search_all[i,j] = GridSearchCV(pipe, param_grid,\n",
    "                                       cv=5, n_jobs=15, verbose=0)\n",
    "        search_all[i,j].fit(X, y);\n",
    "        verbose('%i,%i'%(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_tc,n_conds,figsize=(12,6))\n",
    "for i in range(n_tc):\n",
    "    for j in range(n_conds):\n",
    "        print(\"Best parameter (CV score=%0.3f):\" % search_all[i,j].best_score_)\n",
    "        print(search_all[i,j].best_params_)\n",
    "        if lr:\n",
    "            for k in range(6):\n",
    "                errorfill(test_pca,search_all[i,j].\n",
    "                          cv_results_['mean_test_score']\n",
    "                          .reshape(6,37)[k].T,\n",
    "                          search_all[i,j].cv_results_['std_test_score']\n",
    "                          .reshape(6,37)[k].T/np.sqrt(5), ax=ax[i,j])\n",
    "                ax[i,j].set_ylim(0.4,0.9)\n",
    "            \n",
    "        else:\n",
    "            errorfill(test_pca,search_all[i,j].cv_results_['mean_test_score'],\n",
    "                      search_all[i,j].cv_results_['std_test_score']/np.sqrt(5),\n",
    "                      ax=ax[i,j])    \n",
    "        ax[i,j].set_ylim(0.4,0.95)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to try\n",
    "- Concatenate the conditions C1/C2/C3/C4\n",
    "- Use non-linear methods like kernel methods (but we are already overfitting)\n",
    "- Craft our own Quadratic Discriminant Analysis with diagonal cov matrices\n",
    "- Use L1 penalty + logistic regression (highly relevant to find a relevant low\n",
    "dimensional space)\n",
    "- Use brute force PCA components selection (using all intervals [i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
