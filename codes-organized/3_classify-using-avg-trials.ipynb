{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/data/Project_ASD/' + os.environ[\"USER\"]+'/' #feel free to upload data from /Project_ASD/seyda\n",
    "baseMethod='baseline50'\n",
    "filename = '/X_all-baseline50-floating2.npz'\n",
    "data = np.load(directory+filename, allow_pickle=True)\n",
    "X_all = data['X_all'] # n_trtype, n_conds,n_subj, n_time, n_elec \n",
    "subjects = data['subjects']\n",
    "n_trtype, n_conds,n_subj, n_time, n_elec = X_all.shape\n",
    "subj2exclude=['10594'] #subj2exclude=['10056','12144','12360','1160','12005']\n",
    "ind_ex = [i for i in range(subjects.shape[0]) if subjects[i,2] in subj2exclude]\n",
    "X_all = np.delete(X_all, ind_ex, axis=2)\n",
    "subjects = np.delete(subjects, ind_ex, axis=0)\n",
    "print('Removed '+str(len(ind_ex))+' subjects')\n",
    "#check for nan values. do not delte this. change indices to find nans in dfr dimensions\n",
    "idx = pd.isnull(X_all.mean((0,1,3,4)))== False #RuntimeWarning should be ok\n",
    "X_all = X_all[:,:,idx]\n",
    "subjects = subjects[idx]\n",
    "assert subjects.shape[0] == X_all.shape[2]\n",
    "n_subj = subjects.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 3 different n_pca and 3 regularization parameters\n"
     ]
    }
   ],
   "source": [
    "test_pca = np.arange(1,n_subj,15) #   \n",
    "test_C=np.logspace(-3, 0, 3)  #-3, 0, 41) np.logspace(-5, 0, 6)\n",
    "pca = PCA()\n",
    "param_grid = {'pca__n_components': test_pca,'clf__C': test_C}\n",
    "print('Testing '+ str(param_grid['pca__n_components'].shape[0]) +' different n_pca and '+str(param_grid['clf__C'].shape[0]) +' regularization parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs={}\n",
    "clfs['LR-L2']= LogisticRegression(max_iter=5000, tol=1.0) #default=’l2’\n",
    "clfs['LR-L1']= LogisticRegression(penalty='l1', solver='liblinear', max_iter=5000, tol=1.0)\n",
    "clfs['LDA']=  LinearDiscriminantAnalysis(tol=1e-3)\n",
    "clfs['QDA'] = QuadraticDiscriminantAnalysis(tol=1e-3)\n",
    "clf_key ='LR-L1' #this is the only line you are likely to edit \n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clfs[clf_key])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3\n"
     ]
    }
   ],
   "source": [
    "n_trtype, n_conds,n_subj, n_time, n_elec = X_all.shape\n",
    "y=subjects[...,0]\n",
    "search = np.zeros((n_trtype,5), dtype=object)\n",
    "X_all_40elec=np.take(X_all, range(160)[::4], 4)\n",
    "\n",
    "for i in range(n_trtype):\n",
    "    for j in range(n_conds):\n",
    "        clear_output(wait=True)\n",
    "        print(i, j)\n",
    "        X1 = X_all[i,j].reshape(n_subj,n_time*n_elec)**2        \n",
    "        #X -= X.mean(0, keepdims=True)\n",
    "        #X /= X.std(0, keepdims=True)\n",
    "        search[i,j] = GridSearchCV(pipe, param_grid, cv=5, n_jobs=15, verbose=0)\n",
    "        search[i,j].fit(X1, y);\n",
    "    X2 = X_all_40elec[i].reshape(n_subj,n_time*40*n_conds)**2\n",
    "    search[i,4] = GridSearchCV(pipe, param_grid, cv=5, n_jobs=15, verbose=0)\n",
    "    search[i,4].fit(X2, y);\n",
    "    assert X1.shape == X2.shape\n",
    "    \n",
    "exp_identifier=clf_key+'-'+str(y.shape[0])+'x'+str(X1.shape[1])+'features'+'-pca'+str(param_grid['pca__n_components'].shape[0])+'-C'+str(param_grid['clf__C'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[58.21428571428571, 0.03162277660168379, 16],\n",
       "        [63.21428571428571, 0.03162277660168379, 16],\n",
       "        [54.64285714285714, 0.001, 1],\n",
       "        [63.21428571428571, 0.03162277660168379, 16],\n",
       "        [49.999999999999986, 0.001, 1]],\n",
       "\n",
       "       [[55.35714285714286, 0.001, 1],\n",
       "        [57.857142857142854, 0.001, 1],\n",
       "        [55.35714285714286, 0.001, 1],\n",
       "        [57.857142857142854, 0.001, 1],\n",
       "        [55.00000000000001, 0.03162277660168379, 16]],\n",
       "\n",
       "       [[62.857142857142854, 0.001, 16],\n",
       "        [70.71428571428571, 0.001, 16],\n",
       "        [65.35714285714285, 0.03162277660168379, 16],\n",
       "        [65.71428571428571, 0.001, 1],\n",
       "        [73.92857142857143, 0.03162277660168379, 16]],\n",
       "\n",
       "       [[62.85714285714285, 0.001, 16],\n",
       "        [62.85714285714285, 0.001, 16],\n",
       "        [70.71428571428571, 0.001, 16],\n",
       "        [68.21428571428572, 0.001, 16],\n",
       "        [66.42857142857143, 0.001, 16]],\n",
       "\n",
       "       [[71.07142857142857, 0.001, 1],\n",
       "        [73.92857142857143, 0.001, 1],\n",
       "        [68.92857142857143, 0.001, 1],\n",
       "        [71.42857142857143, 0.001, 1],\n",
       "        [53.214285714285715, 0.03162277660168379, 1]],\n",
       "\n",
       "       [[60.71428571428571, 0.03162277660168379, 1],\n",
       "        [59.999999999999986, 0.03162277660168379, 16],\n",
       "        [55.00000000000001, 0.001, 1],\n",
       "        [57.857142857142854, 0.001, 1],\n",
       "        [60.0, 0.03162277660168379, 16]],\n",
       "\n",
       "       [[65.71428571428571, 0.03162277660168379, 16],\n",
       "        [54.99999999999999, 0.03162277660168379, 16],\n",
       "        [57.857142857142854, 0.001, 1],\n",
       "        [60.357142857142854, 0.03162277660168379, 1],\n",
       "        [57.857142857142854, 0.03162277660168379, 16]],\n",
       "\n",
       "       [[62.85714285714285, 0.001, 16],\n",
       "        [54.99999999999999, 0.03162277660168379, 1],\n",
       "        [60.71428571428571, 0.03162277660168379, 16],\n",
       "        [59.64285714285713, 0.001, 16],\n",
       "        [58.57142857142858, 0.03162277660168379, 1]]], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate and write best scores \n",
    "import time\n",
    "year, month, day, hour, min = map(str, time.strftime(\"%Y %m %d %H %M\").split())\n",
    "\n",
    "best = np.zeros((n_trtype,5,3), dtype=object)\n",
    "for i in range(n_trtype):\n",
    "    for j in range(5):\n",
    "        best[i,j,0]=search[i,j].best_score_*100\n",
    "        best[i,j,1]=search[i,j].best_params_['clf__C']\n",
    "        best[i,j,2]=search[i,j].best_params_['pca__n_components']\n",
    "with open('best.csv','a') as fd:\n",
    "    fd.write(\"\\n\"+ year+'-'+month+'-'+day+'-'+hour+min+\"\\n\")\n",
    "    fd.write(exp_identifier+\"\\n\")   \n",
    "    fd.write(str(best)+\"\\n\")\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add notes if you want \n",
    "#with open('best.csv','a') as fd:\n",
    "#    fd.write(\"Now I will starting to use the real dataset with all four conditions. recently calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cv_results  \n",
    "mean_score = np.zeros((n_trtype,5), dtype=object)\n",
    "std_score = np.zeros((n_trtype,5), dtype=object)\n",
    "for i in range(n_trtype):\n",
    "    for j in range(5):\n",
    "        for k in range(test_C.shape[0]):\n",
    "            std_score[i,j]=search[i,j].cv_results_['std_test_score'].reshape(test_C.shape[0],test_pca.shape[0])\n",
    "            mean_score[i,j]=search[i,j].cv_results_['mean_test_score'].reshape(test_C.shape[0],test_pca.shape[0])\n",
    "#exp_identifier looks like this: LR-L2-pca12-C21-78080features\n",
    "save_name=year+'-'+month+'-'+day+'-'+hour+min+'-'+exp_identifier+'.npz' \n",
    "np.savez(directory+'/scores/'+save_name, mean_score=mean_score, std_score=std_score,test_C=test_C,test_pca=test_pca,best=best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X_all[i,:,j].reshape(n_conds,n_time*n_elec)**2        \n",
    "search[i,j] = GridSearchCV(pipe, param_grid, cv=2, n_jobs=15, verbose=0) #cv is number of splits \n",
    "search[i,j].fit(X1, y);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37\n"
     ]
    }
   ],
   "source": [
    "# COMPARE SUBJECT SCORES, DECODING CONDITIONS \n",
    "# n_trtype, n_conds,n_subj, n_time, n_elec = X_all.shape\n",
    "\n",
    "test_pca =np.array([1,5,10,20,30]) \n",
    "test_C=np.logspace(-3, 0, 4) \n",
    "pca = PCA()\n",
    "param_grid = {'pca__n_components': test_pca,'clf__C': test_C}\n",
    "clf_key ='LR-L1' #this is the only line you are likely to edit \n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clfs[clf_key])])\n",
    "\n",
    "y=np.arange(1,5,1)\n",
    "y=np.concatenate((y,y,y,y,y,y,y,y),axis=0)\n",
    "search = np.zeros((n_subj), dtype=object)\n",
    "\n",
    "for j in range(n_subj):\n",
    "    clear_output(wait=True)\n",
    "    print(i, j)\n",
    "    X1 = X_all[:,:,j].reshape(n_trtype*n_conds,n_time*n_elec)**2        \n",
    "    search[j] = GridSearchCV(pipe, param_grid, cv=4, n_jobs=15, verbose=0) #cv is number of splits \n",
    "    search[j].fit(X1, y);\n",
    "\n",
    "exp_identifier=clf_key+'-compareSubjScores-'+str(y.shape[0])+'x'+str(X1.shape[1])+'features'+'-pca'+str(param_grid['pca__n_components'].shape[0])+'-C'+str(param_grid['clf__C'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50.0, 0.1, 20],\n",
       "       [50.0, 1.0, 20],\n",
       "       [40.625, 0.01, 20],\n",
       "       [37.5, 0.01, 1],\n",
       "       [37.5, 0.001, 10],\n",
       "       [40.625, 0.1, 10],\n",
       "       [37.5, 1.0, 20],\n",
       "       [37.5, 0.01, 20],\n",
       "       [40.625, 0.001, 10],\n",
       "       [40.625, 0.001, 5],\n",
       "       [50.0, 1.0, 20],\n",
       "       [37.5, 0.001, 1],\n",
       "       [56.25, 0.1, 20],\n",
       "       [40.625, 0.01, 10],\n",
       "       [37.5, 0.01, 10],\n",
       "       [37.5, 0.01, 5],\n",
       "       [43.75, 1.0, 10],\n",
       "       [34.375, 1.0, 5],\n",
       "       [43.75, 0.001, 5],\n",
       "       [40.625, 0.01, 20],\n",
       "       [43.75, 1.0, 20],\n",
       "       [46.875, 0.01, 20],\n",
       "       [50.0, 1.0, 20],\n",
       "       [37.5, 0.01, 10],\n",
       "       [40.625, 0.1, 20],\n",
       "       [37.5, 0.01, 20],\n",
       "       [43.75, 1.0, 20],\n",
       "       [43.75, 0.01, 20],\n",
       "       [43.75, 0.01, 10],\n",
       "       [50.0, 0.1, 20],\n",
       "       [40.625, 0.01, 10],\n",
       "       [31.25, 0.001, 5],\n",
       "       [43.75, 0.001, 20],\n",
       "       [40.625, 0.01, 20],\n",
       "       [56.25, 1.0, 20],\n",
       "       [53.125, 0.1, 20],\n",
       "       [53.125, 1.0, 20],\n",
       "       [53.125, 1.0, 5]], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate and write best scores \n",
    "import time\n",
    "year, month, day, hour, min = map(str, time.strftime(\"%Y %m %d %H %M\").split())\n",
    "\n",
    "best = np.zeros((n_subj,3), dtype=object)\n",
    "for j in range(n_subj):\n",
    "    best[j,0]=search[j].best_score_*100\n",
    "    best[j,1]=search[j].best_params_['clf__C']\n",
    "    best[j,2]=search[j].best_params_['pca__n_components']\n",
    "with open('best.csv','a') as fd:\n",
    "    fd.write(\"\\n\"+ year+'-'+month+'-'+day+'-'+hour+min+\"\\n\")\n",
    "    fd.write(exp_identifier+\"\\n\")   \n",
    "    fd.write(str(best)+\"\\n\")\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cv_results  \n",
    "mean_score = np.zeros((n_subj), dtype=object)\n",
    "std_score = np.zeros((n_subj), dtype=object)\n",
    "for j in range(n_subj):\n",
    "    for k in range(test_C.shape[0]):\n",
    "        std_score[j]=search[j].cv_results_['std_test_score'].reshape(test_C.shape[0],test_pca.shape[0])\n",
    "        mean_score[j]=search[j].cv_results_['mean_test_score'].reshape(test_C.shape[0],test_pca.shape[0])\n",
    "#exp_identifier looks like this: LR-L2-pca12-C21-78080features\n",
    "save_name=year+'-'+month+'-'+day+'-'+hour+min+'-'+exp_identifier+'.npz' \n",
    "np.savez(directory+'/scores/'+save_name, mean_score=mean_score, std_score=std_score,test_C=test_C,test_pca=test_pca,best=best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE SUCCESS RATES  ACROSS TIME INTERVALS \n",
    "# IN PROGRESS\n",
    "# n_trtype, n_conds,n_subj, n_time, n_elec = X_all.shape\n",
    "\n",
    "test_pca =np.array([1,4]) \n",
    "test_C=np.logspace(-3, 0, 10) \n",
    "pca = PCA()\n",
    "param_grid = {'pca__n_components': test_pca,'clf__C': test_C}\n",
    "clf_key ='LR-L1' #this is the only line you are likely to edit \n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clfs[clf_key])])\n",
    "\n",
    "y=np.arange(0,8,1)\n",
    "y=np.concatenate((y,y,y,y),axis=0)\n",
    "search = np.zeros((n_subj), dtype=object)\n",
    "\n",
    "from ms2time import ms2time\n",
    "for w in range(9):\n",
    "    ind_time=ms2time(w*100+50, w*100+150)\n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
